{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSYvP0n8RjYH"
      },
      "source": [
        "# Frequent itemset mining\n",
        "\n",
        "- Student ID: 21127191\n",
        "- Student name: Nguyễn Nhật Truyền\n",
        "\n",
        "**How to do your homework**\n",
        "\n",
        "\n",
        "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
        "\n",
        "You can discuss ideas with classmates as well as finding information from the internet, book, etc...; but *this homework must be your*.\n",
        "\n",
        "**How to submit your homework**\n",
        "\n",
        "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
        "\n",
        "Then create a folder named `ID` (for example, if your ID is 1234567, then name the folder `1234567`) Copy file notebook to this folder, compress and submit it on moodle.\n",
        "\n",
        "**Contents:**\n",
        "\n",
        "- Frequent itemset mining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXZ5gCVaRjYa"
      },
      "source": [
        "# 1. Preliminaries\n",
        "## This is how it all started ...\n",
        "- Rakesh Agrawal, Tomasz Imielinski, Arun N. Swami: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Conference 1993: 207-216\n",
        "- Rakesh Agrawal, Ramakrishnan Srikant: Fast Algorithms for Mining Association Rules in Large Databases. VLDB 1994: 487-499\n",
        "\n",
        "**These two papers are credited with the birth of Data Mining**\n",
        "## Frequent itemset mining (FIM)\n",
        "\n",
        "Find combinations of items (itemsets) that occur frequently.\n",
        "## Applications\n",
        "- Items = products, transactions = sets of products someone bought in one trip to the store.\n",
        "$\\Rightarrow$ items people frequently buy together.\n",
        "    + Example: if people usually buy bread and coffee together, we run a sale of bread to attract people attention and raise price of coffee.\n",
        "- Items = webpages, transactions = words. Unusual words appearing together in a large number of documents, e.g., “Brad” and “Angelina,” may indicate an interesting relationship.\n",
        "- Transactions = Sentences, Items = Documents containing those sentences. Items that appear together too often could represent plagiarism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8vAJ8A2RjYi"
      },
      "source": [
        "## Transactional Database\n",
        "A transactional database $D$ consists of $N$ transactions: $D=\\left\\{T_1,T_2,...,T_N\\right\\}$. A transaction $T_n \\in D (1 \\le n \\le N)$ contains one or more items and that $I= \\left\\{ i_1,i_2,…,i_M \\right\\}$ is the set of distinct items in $D$, $T_n \\subset I$. Commonly, a transactional database is represented by a flat file instead of a database system: items are non-negative integers, each row represents a transaction, items in a transaction separated by space.\n",
        "\n",
        "Example:\n",
        "\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n",
        "\n",
        "30 31 32\n",
        "\n",
        "33 34 35\n",
        "\n",
        "36 37 38 39 40 41 42 43 44 45 46\n",
        "\n",
        "38 39 47 48\n",
        "\n",
        "38 39 48 49 50 51 52 53 54 55 56 57 58\n",
        "\n",
        "32 41 59 60 61 62\n",
        "\n",
        "3 39 48\n",
        "\n",
        "63 64 65 66 67 68\n",
        "\n",
        "\n",
        "\n",
        "# Definition\n",
        "\n",
        "- Itemset: A collection of one or more items.\n",
        "    + Example: {1 4 5}\n",
        "- **k-itemset**: An itemset that contains k items.\n",
        "- Support: Frequency of occurrence of an itemset.\n",
        "    + Example: From the example above, item 3 appear in 2 transactions so its support is 2.\n",
        "- Frequent itemset: An itemset whose support is greater than or equal to a `minsup` threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdykKxr6RjY-"
      },
      "source": [
        "# The Apriori Principle\n",
        "- If an itemset is frequent, then all of its subsets must also be frequent.\n",
        "- If an itemset is not frequent, then all of its supersets cannot be frequent.\n",
        "- The support of an itemset never exceeds the support of its subsets.\n",
        "$$ \\forall{X,Y}: (X \\subseteq Y) \\Rightarrow s(X)\\ge s(Y)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvfMR7-CRjZB"
      },
      "source": [
        "# 2. Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9gZh4DORjZD"
      },
      "source": [
        "## The Apriori algorithm\n",
        "Suppose:\n",
        "\n",
        "$C_k$ candidate itemsets of size k.\n",
        "\n",
        "$L_k$ frequent itemsets of size k.\n",
        "\n",
        "The level-wise approach of Apriori algorithm can be descibed as follow:\n",
        "1. k=1, $C_k$ = all items.\n",
        "2. While $C_k$ not empty:\n",
        "    3. Scan the database to find which itemsets in $C_k$ are frequent and put them into $L_k$.\n",
        "    4. Use $L_k$ to generate a collection of candidate itemsets $C_{k+1}$ of size k+1.\n",
        "    5. k=k+1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF9xHOBLRjZJ"
      },
      "source": [
        "### Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7F0lUOSuRjZN"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OogwdcLRjZf"
      },
      "source": [
        "### Read data\n",
        "First we have to read data from database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "U2bsGrTERjZg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def readData(path):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    --------------------------\n",
        "        path: path of database D.\n",
        "\n",
        "    --------------------------\n",
        "    Returns\n",
        "        data: a dictionary for representing database D\n",
        "                 - keys: transaction tids\n",
        "                 - values: itemsets.\n",
        "        s: support of distict items in D.\n",
        "    \"\"\"\n",
        "    data={}\n",
        "    s=defaultdict(lambda: 0) #* Initialize a dictionary for storing support of items in I.\n",
        "    with open(path,'rt') as f:\n",
        "        tid=1;\n",
        "        for line in f:\n",
        "            itemset=set(map(int,line.split())) #* A python set is a native way for storing an itemset.\n",
        "            for item in itemset:\n",
        "                s[item]+=1     #* Why don't we compute support of items while reading data?\n",
        "            data[tid]= itemset\n",
        "            tid+=1\n",
        "    return data, s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSTC78WURjZu"
      },
      "source": [
        "### Tree Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGAkmuXtRjZw"
      },
      "source": [
        "**Question 0: I gave you pseudo code of Apriori algorithm above but we implement Tree Projection. Tell me the differences of two algorithms.**\n",
        "\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BVRT5BnWRjZz"
      },
      "outputs": [],
      "source": [
        "def joinset(a,b):\n",
        "    '''\n",
        "    Parameters\n",
        "    -------------------\n",
        "        2 itemsets a and b (of course they are at same branch in search space)\n",
        "\n",
        "    -------------------\n",
        "    return\n",
        "        ret: itemset generated by joining a and b\n",
        "    '''\n",
        "    # a,b same brach -> a_k = b_k\n",
        "    # Hint: this function will be called in generateSearchSpace method.:\n",
        "    sa = set(a)\n",
        "    sb = set(b)\n",
        "    ret = sa.union(sb)\n",
        "    ret = list(ret)\n",
        "    ret.sort()\n",
        "    return ret\n",
        "\n",
        "class TP:\n",
        "    def __init__ (self, data=None, s=None, minSup=None):\n",
        "        self.data=data\n",
        "        self.s={}\n",
        "\n",
        "\n",
        "        for key, support in sorted(s.items(),key= lambda item: item[1]):\n",
        "            self.s[key]=support\n",
        "        # Why should we do this, answer it at the markdown below?\n",
        "\n",
        "        self.minSup=minSup\n",
        "        self.L={}  #Store frequent itemsets mined from database\n",
        "        self.runAlgorithm()\n",
        "    def initialize(self):\n",
        "        \"\"\"\n",
        "        Initialize search space at first step\n",
        "        --------------------------------------\n",
        "        We represent our search space in a tree structure\n",
        "        \"\"\"\n",
        "        tree={}\n",
        "\n",
        "        search_space={}\n",
        "        for item, support in self.s.items():\n",
        "            search_space[item]={}\n",
        "\n",
        "            search_space[item]['itemset']=[item]\n",
        "            '''\n",
        "            python set does not remain elements order\n",
        "            so we use a list to extend it easily when create new itemset\n",
        "            but why we store itemset in data by a python set???? '''\n",
        "            # TODO: study about python set and its advantages,\n",
        "            # answer at the markdown below.\n",
        "\n",
        "            search_space[item]['pruned']=False\n",
        "\n",
        "\n",
        "            search_space[item]['support']=support\n",
        "\n",
        "            tree[item]={}\n",
        "            '''\n",
        "            Why should i store an additional tree (here it called tree)?\n",
        "            Answer: This really help in next steps.\n",
        "\n",
        "            Remember that there is always a big gap from theory to practicality\n",
        "            and implementing this algorithm in python is not as simple as you think.\n",
        "            '''\n",
        "\n",
        "        return tree, search_space\n",
        "\n",
        "    def computeItemsetSupport(self, itemset):\n",
        "\n",
        "        '''Return support of itemset'''\n",
        "        # TODO (hint: this is why i use python set in data)\n",
        "        support = 0\n",
        "        for transaction in self.data.values():\n",
        "          if set(itemset).issubset(set(transaction)):\n",
        "            support += 1\n",
        "        return support\n",
        "\n",
        "\n",
        "\n",
        "    def prune(self,k, tree, search_space):\n",
        "\n",
        "        '''\n",
        "        In this method we will find out which itemset in current search space is frequent\n",
        "        itemset then add it to L[k]. In addition, we prune those are not frequent itemsets.\n",
        "        '''\n",
        "        #TODO\n",
        "        pruned_items = []\n",
        "\n",
        "        for item, info in search_space.items():\n",
        "            if info['support'] >= self.minSup:\n",
        "                self.L.setdefault(k, [])\n",
        "                self.L[k].append((info['itemset'], info['support']))\n",
        "            else:\n",
        "                pruned_items.append(item)\n",
        "\n",
        "        for item in pruned_items:\n",
        "            search_space[item]['pruned'] = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generateSearchSpace(self,k, tree, search_space):\n",
        "        '''\n",
        "        Generate search space for exploring k+1 itemset. (Recursive function)\n",
        "        '''\n",
        "        items=list(tree.keys())\n",
        "\n",
        "        ''' print search_space.keys() you will understand\n",
        "         why we need an additional tree, '''\n",
        "        l=len(items)\n",
        "        self.prune(k, tree, search_space)\n",
        "        if l==0: return   #Stop condition\n",
        "\n",
        "        for i in range(l-1):\n",
        "            a=items[i]\n",
        "            if search_space[a]['pruned']: continue\n",
        "\n",
        "\n",
        "            for j in range(i+1,l):\n",
        "                b=items[j]\n",
        "\n",
        "                search_space[a][b]={}\n",
        "                tree[a][b]={}\n",
        "                #TODO\n",
        "                # You really need to understand what am i doing here before doing work below.\n",
        "                # (Hint: draw tree and search space to draft).\n",
        "\n",
        "                #First create newset using join set\n",
        "                newset = joinset(search_space[a]['itemset'], search_space[b]['itemset'])\n",
        "\n",
        "                #Second add newset to search_space\n",
        "                search_space[a][b]['itemset'] = newset\n",
        "                search_space[a][b]['pruned'] = False\n",
        "                search_space[a][b]['support'] = self.computeItemsetSupport(newset)\n",
        "                tree[a][b] = search_space[a][b]\n",
        "            #  Generate search_space for k+1-itemset\n",
        "            search_space[a].pop('itemset')\n",
        "            search_space[a].pop('pruned')\n",
        "            search_space[a].pop('support')\n",
        "            self.generateSearchSpace(k+1,tree[a],search_space[a])\n",
        "\n",
        "\n",
        "    def runAlgorithm(self):\n",
        "        tree,search_space=self.initialize() #generate search space for 1-itemset\n",
        "        self.generateSearchSpace(1, tree, search_space)\n",
        "    def miningResults(self):\n",
        "        return self.L\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tMTpwxLRjZ-"
      },
      "source": [
        "Ok, let's test on a typical dataset `chess`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "gLygYqiYRjZ-"
      },
      "outputs": [],
      "source": [
        "transactions, freq= readData('chess.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "PnxbU77YRjaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56961353-e1d6-429a-c469-e4ea6aa8612d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, [([48], 3013), ([56], 3021), ([66], 3021), ([34], 3040), ([62], 3060), ([7], 3076), ([36], 3099), ([60], 3149), ([40], 3170), ([29], 3181), ([52], 3185), ([58], 3195)])\n",
            "(2, [([48, 52], 3002), ([48, 58], 3012), ([29, 56], 3006), ([52, 56], 3016), ([56, 58], 3020), ([60, 66], 3021), ([29, 66], 3013), ([52, 66], 3010), ([58, 66], 3020), ([34, 40], 3017), ([29, 34], 3036), ([34, 52], 3031), ([34, 58], 3039), ([60, 62], 3014), ([40, 62], 3045), ([29, 62], 3045), ([52, 62], 3049), ([58, 62], 3060), ([7, 60], 3031), ([7, 40], 3050), ([7, 29], 3069), ([7, 52], 3065), ([7, 58], 3075), ([36, 60], 3052), ([36, 40], 3073), ([29, 36], 3084), ([36, 52], 3088), ([36, 58], 3098), ([40, 60], 3124), ([29, 60], 3136), ([52, 60], 3138), ([58, 60], 3148), ([29, 40], 3155), ([40, 52], 3159), ([40, 58], 3169), ([29, 52], 3170), ([29, 58], 3180), ([52, 58], 3184)])\n",
            "(3, [([48, 52, 58], 3001), ([29, 52, 56], 3001), ([29, 56, 58], 3005), ([52, 56, 58], 3015), ([29, 60, 66], 3013), ([52, 60, 66], 3010), ([58, 60, 66], 3020), ([29, 52, 66], 3002), ([29, 58, 66], 3012), ([52, 58, 66], 3009), ([29, 34, 40], 3013), ([34, 40, 52], 3008), ([34, 40, 58], 3016), ([29, 34, 52], 3027), ([29, 34, 58], 3035), ([34, 52, 58], 3030), ([29, 60, 62], 3001), ([52, 60, 62], 3003), ([58, 60, 62], 3014), ([29, 40, 62], 3030), ([40, 52, 62], 3034), ([40, 58, 62], 3045), ([29, 52, 62], 3034), ([29, 58, 62], 3045), ([52, 58, 62], 3049), ([7, 40, 60], 3006), ([7, 29, 60], 3024), ([7, 52, 60], 3020), ([7, 58, 60], 3030), ([7, 29, 40], 3043), ([7, 40, 52], 3039), ([7, 40, 58], 3049), ([7, 29, 52], 3058), ([7, 29, 58], 3068), ([7, 52, 58], 3064), ([36, 40, 60], 3027), ([29, 36, 60], 3039), ([36, 52, 60], 3041), ([36, 58, 60], 3051), ([29, 36, 40], 3058), ([36, 40, 52], 3062), ([36, 40, 58], 3072), ([29, 36, 52], 3073), ([29, 36, 58], 3083), ([36, 52, 58], 3087), ([29, 40, 60], 3111), ([40, 52, 60], 3113), ([40, 58, 60], 3123), ([29, 52, 60], 3125), ([29, 58, 60], 3135), ([52, 58, 60], 3137), ([29, 40, 52], 3144), ([29, 40, 58], 3154), ([40, 52, 58], 3158), ([29, 52, 58], 3169)])\n",
            "(4, [([29, 52, 56, 58], 3000), ([29, 52, 60, 66], 3002), ([29, 58, 60, 66], 3012), ([52, 58, 60, 66], 3009), ([29, 52, 58, 66], 3001), ([29, 34, 40, 52], 3004), ([29, 34, 40, 58], 3012), ([34, 40, 52, 58], 3007), ([29, 34, 52, 58], 3026), ([29, 58, 60, 62], 3001), ([52, 58, 60, 62], 3003), ([29, 40, 52, 62], 3019), ([29, 40, 58, 62], 3030), ([40, 52, 58, 62], 3034), ([29, 52, 58, 62], 3034), ([7, 40, 58, 60], 3005), ([7, 29, 52, 60], 3013), ([7, 29, 58, 60], 3023), ([7, 52, 58, 60], 3019), ([7, 29, 40, 52], 3032), ([7, 29, 40, 58], 3042), ([7, 40, 52, 58], 3038), ([7, 29, 52, 58], 3057), ([29, 36, 40, 60], 3014), ([36, 40, 52, 60], 3016), ([36, 40, 58, 60], 3026), ([29, 36, 52, 60], 3028), ([29, 36, 58, 60], 3038), ([36, 52, 58, 60], 3040), ([29, 36, 40, 52], 3047), ([29, 36, 40, 58], 3057), ([36, 40, 52, 58], 3061), ([29, 36, 52, 58], 3072), ([29, 40, 52, 60], 3100), ([29, 40, 58, 60], 3110), ([40, 52, 58, 60], 3112), ([29, 52, 58, 60], 3124), ([29, 40, 52, 58], 3143)])\n",
            "(5, [([29, 52, 58, 60, 66], 3001), ([29, 34, 40, 52, 58], 3003), ([29, 40, 52, 58, 62], 3019), ([7, 29, 52, 58, 60], 3012), ([7, 29, 40, 52, 58], 3031), ([29, 36, 40, 52, 60], 3003), ([29, 36, 40, 58, 60], 3013), ([36, 40, 52, 58, 60], 3015), ([29, 36, 52, 58, 60], 3027), ([29, 36, 40, 52, 58], 3046), ([29, 40, 52, 58, 60], 3099)])\n",
            "(6, [([29, 36, 40, 52, 58, 60], 3002)])\n"
          ]
        }
      ],
      "source": [
        "# Run and print result (better print format)\n",
        "a=TP(data=transactions,s=freq, minSup=3000)\n",
        "print(*a.miningResults().items(),sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp0RFbw-RjaU"
      },
      "source": [
        "### Answer questions here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCNkCtW8us9F"
      },
      "source": [
        "**Question 1. Why should we sort all items in s by it's support and why we have to restored it to new artribute s?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "*   Sorting all items in s by their support is done to prioritize the processing of items with higher support during the Apriori algorithm. This is a common optimization strategy in frequent itemset mining algorithms.\n",
        "*   The reason for storing the sorted items in a new attribute self.s is to have a sorted representation of items based on their support. This sorted order is used when initializing the search space (tree and search_space structures). Sorting allows the algorithm to start with items that have lower support, making the search space generation and pruning more efficient.\n",
        "*   The sorting step helps to organize the items in a way that facilitates early pruning of infrequent itemsets, leading to faster execution of the Apriori algorithm.\n",
        "\n",
        "\n",
        "**Question 2. Python set does not remain elements order so we use a list to extend it easily when create new itemset but why we store itemset in data by a python set????**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "*   The reason for using a Python set in the data dictionary to store itemsets is to take advantage of the set's mathematical properties, specifically the ability to efficiently check for subset relationships.\n",
        "*   When checking if one itemset is a subset of another, the order of elements does not matter, and using sets allows for quick and efficient subset checks. This is crucial when determining the support of an itemset within a transaction.\n",
        "\n",
        "*   Beside, using a list to extend and create new itemsets (as seen in the joinset function) is helpful during the generation of candidate itemsets in the search space. Lists maintain the order of elements, which is important when creating new combinations of items. So, sets are used for efficient membership tests, while lists are used for maintaining order during the candidate generation process.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Question 3.  After finish implementing the algorithm tell me why should you use this instead of delete item directly from search_space and tree.**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "*   Tree Projection is a technique used to avoid recomputing support counts for itemsets from scratch in each level of the search space. Instead of deleting items directly from search_space and tree and recomputing support for each iteration, Tree Projection leverages the support information already calculated in previous levels.\n",
        "*   Deleting items directly from the structures would require re-evaluating the support of each itemset at every level of the search space. This can be computationally expensive, especially when dealing with large datasets and deep search spaces.\n",
        "\n",
        "*   By using Tree Projection, the algorithm takes advantage of the fact that the support of an itemset can be projected down the tree from higher levels to lower levels. This reduces the computational cost and speeds up the execution of the Apriori algorithm.\n",
        "\n",
        "*   Tree Projection is an optimization that helps avoid redundant calculations and improves the efficiency of the frequent itemset mining process.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnVm8wYIRjaV"
      },
      "source": [
        "# 3. Churn analysis\n",
        "\n",
        "In this section, you will use frequent itemset mining technique to analyze `churn` dataset (for any purposes). You can download dataset from here: http://ce.sharif.edu/courses/85-86/1/ce925/assignments/files/assignDir2/churn.txt. Write your report and implementation below.\n",
        "\n",
        "*Remember this dataset is not represented as a transactional database, first thing that you have to do is transforming it into a flat file.  \n",
        "More information about `churn` here: http://ce.sharif.edu/courses/85-86/1/ce925/assignments/files/assignDir4/Churn.pdf)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9U08alVRjaW"
      },
      "source": [
        "**TODO:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FzxGs7RRjaX"
      },
      "source": [
        "# 4 References\n",
        "\n",
        "http://ce.sharif.edu/courses/85-86/1/ce925/assignments/files/assignDir2/ProjectDefinition1.pdf\n",
        "\n",
        "https://cs.wmich.edu/~alfuqaha/summer14/cs6530/lectures/AssociationAnalysis-Part1.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doYH4biqR_N7"
      },
      "source": [
        "Feel free to send questions to my email address: nnduc@fit.hcmus.edu.vn\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}