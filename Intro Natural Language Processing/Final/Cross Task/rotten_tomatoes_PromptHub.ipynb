{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRg8TY9dIl_l",
        "outputId": "4ebb382c-765b-4f8c-8bbc-69b6239f0086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Prompt-Transferability' already exists and is not an empty directory.\n",
            "/content/Prompt-Transferability/Prompt-Transferability-2.0-latest/Prompt-Transferability\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.10 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.35.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.25.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.16.0)\n",
            "Requirement already satisfied: openprompt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10->-r requirements.txt (line 2)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.10/dist-packages (from openprompt->-r requirements.txt (line 5)) (0.1.96)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from openprompt->-r requirements.txt (line 5)) (2.6.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from openprompt->-r requirements.txt (line 5)) (3.8.1)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (from openprompt->-r requirements.txt (line 5)) (0.1.8)\n",
            "Requirement already satisfied: rouge==1.0.0 in /usr/local/lib/python3.10/dist-packages (from openprompt->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from openprompt->-r requirements.txt (line 5)) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge==1.0.0->openprompt->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10->-r requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->openprompt->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->openprompt->-r requirements.txt (line 5)) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chengjiali/Prompt-Transferability.git\n",
        "%cd Prompt-Transferability\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GEREz7aV4Bs",
        "outputId": "5724431c-2c07-4100-e063-3b6ef51b9897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu111 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Prompt-Transferability-2.0-latest/"
      ],
      "metadata": {
        "id": "lwCVY74TRtUH",
        "outputId": "16e0df39-8e26-49ba-e88d-ce617a155e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Prompt-Transferability/Prompt-Transferability-2.0-latest/Prompt-Transferability/Prompt-Transferability-2.0-latest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from transformers import (\n",
        "    set_seed,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EvalPrediction,\n",
        "    default_data_collator,\n",
        ")\n",
        "from openprompt.data_utils.utils import InputExample\n",
        "from openprompt import PromptDataLoader, PromptForClassification\n",
        "from openprompt.plms import load_plm\n",
        "from openprompt.prompts import SoftTemplate, ManualVerbalizer\n",
        "\n",
        "from prompt_hub import task_to_keys, get_model\n",
        "from prompt_hub.hub import PromptHub\n",
        "from prompt_hub.training_args import PromptTrainingArguments, RemainArgHfArgumentParser"
      ],
      "metadata": {
        "id": "sgeTRFsCaxB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train prompt\n",
        "\n",
        "Let's first generate a config and convert it into `huggingface.TrainingArguments`."
      ],
      "metadata": {
        "id": "YWVda1fhXcGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"do_test\": True,\n",
        "    \"prompt_len\": 100,\n",
        "    \"num_proj_layers\": 1,\n",
        "    \"flatten_proj\": True,\n",
        "    \"max_steps\": 100,\n",
        "    \"eval_steps\": 10,\n",
        "    \"save_steps\": 10,\n",
        "    \"logging_steps\": 2,\n",
        "    \"per_device_train_batch_size\": 16,\n",
        "    \"per_device_eval_batch_size\": 128,\n",
        "    \"learning_rate\": 5e-4,\n",
        "    \"lr_scheduler_type\": 'constant',\n",
        "    \"warmup_steps\": 0,\n",
        "\n",
        "    \"save_total_limit\": 1,\n",
        "    \"predict_with_generate\": True,\n",
        "    \"load_best_model_at_end\": True,\n",
        "    \"metric_for_best_model\": \"combined_score\",\n",
        "    \"greater_is_better\": True,\n",
        "    \"evaluation_strategy\": \"steps\",\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"save_strategy\": \"steps\",\n",
        "    \"model_parallel\": False\n",
        "}\n",
        "\n",
        "args = PromptTrainingArguments(\n",
        "    output_dir='outputs',\n",
        "    backbone='roberta-base',\n",
        "    dataset='rotten_tomatoes',\n",
        "    prompt_len=100\n",
        ")\n",
        "\n",
        "for k, v in config.items():\n",
        "  setattr(args, k, v)"
      ],
      "metadata": {
        "id": "b50tNt4qXUt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(args.seed)\n",
        "\n",
        "is_regression = args.dataset in ['stsb']\n",
        "\n",
        "metric = load_metric(\"prompt_hub/glue_metrics.py\", args.dataset)\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)\n",
        "    result = metric.compute(predictions=preds, references=p.label_ids)\n",
        "    result[\"combined_score\"] = np.mean(list(result.values())).item()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "B7TIN2VuTesf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4082588-903b-4ac3-a2e8-e2bb54f49d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:848: FutureWarning: The repository for glue_metrics contains custom code which must be executed to correctly load the metric. You can inspect the repository content at prompt_hub/glue_metrics.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = PromptHub(\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "PJR7nGrB6sBU",
        "outputId": "c56e49ed-caef-44fe-ffd7-e92a5611690d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters:\n",
            "prompt_model.template.soft_embeds torch.Size([100, 768])\n",
            "Template: SoftTemplate(\n",
            "  (raw_embedding): Embedding(50265, 768, padding_idx=1)\n",
            ")\n",
            "Verbalizer: ManualVerbalizer()\n",
            "Raw input example: {\n",
            "  \"guid\": 0,\n",
            "  \"label\": 1,\n",
            "  \"meta\": {},\n",
            "  \"text_a\": \"the rock is destined to be the 21st century's new \\\" conan \\\" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\",\n",
            "  \"text_b\": \"\",\n",
            "  \"tgt_text\": null\n",
            "}\n",
            "\n",
            "Wrapped input example: [[{'text': '', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': ' the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' ', 'loss_ids': 0, 'shortenable_ids': 1}], {'guid': 0, 'label': 1}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cấu trúc input\n",
        "trainer.template.text"
      ],
      "metadata": {
        "id": "N3nXm8xqR74n",
        "outputId": "b49ccb76-a8a6-45be-a154-1cc2ec1b65f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'add_prefix_space': '', 'soft': None, 'duplicate': 100, 'same': True},\n",
              " {'add_prefix_space': ' ', 'mask': None},\n",
              " {'add_prefix_space': ' ', 'placeholder': 'text_a'},\n",
              " {'add_prefix_space': ' ', 'placeholder': 'text_b'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# độ dài soft prompt\n",
        "trainer.template.num_tokens"
      ],
      "metadata": {
        "id": "YakTAMkNSI_k",
        "outputId": "852e6a2f-4fff-44bd-97f7-610955dab1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kích thước prompt embedding (num_tokens, embedding_dim)\n",
        "trainer.template.soft_embeds.shape"
      ],
      "metadata": {
        "id": "sJf83gwNSQH7",
        "outputId": "aed7f43d-921a-477c-d3bb-3de3f11b071a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mô hình\n",
        "args.backbone"
      ],
      "metadata": {
        "id": "XGAexobYSVqN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "57b8a2ef-9d04-4d90-bb92-21bd56b697f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'roberta-base'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tác vụ\n",
        "args.dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cR3F6SLnbMpW",
        "outputId": "b195d762-9dbd-464d-e0c7-77efdc8635c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rotten_tomatoes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Prompt\n",
        "\n",
        "To save time, we use a pretrained prompt."
      ],
      "metadata": {
        "id": "iEJAaqkV3GZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train_prompt(args.backbone, args.dataset)"
      ],
      "metadata": {
        "id": "OQtCeMMo3FJA",
        "outputId": "8b73819e-0ee2-474c-c8c3-03e83e84550f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing: 8530it [00:07, 1163.22it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 04:13, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Combined Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.622200</td>\n",
              "      <td>0.656431</td>\n",
              "      <td>63.320826</td>\n",
              "      <td>63.320826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.714100</td>\n",
              "      <td>0.631427</td>\n",
              "      <td>64.634146</td>\n",
              "      <td>64.634146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.627700</td>\n",
              "      <td>0.611055</td>\n",
              "      <td>66.697936</td>\n",
              "      <td>66.697936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.566900</td>\n",
              "      <td>0.593935</td>\n",
              "      <td>68.761726</td>\n",
              "      <td>68.761726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.613400</td>\n",
              "      <td>0.573224</td>\n",
              "      <td>71.294559</td>\n",
              "      <td>71.294559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.590900</td>\n",
              "      <td>0.560099</td>\n",
              "      <td>72.420263</td>\n",
              "      <td>72.420263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.609800</td>\n",
              "      <td>0.550776</td>\n",
              "      <td>73.170732</td>\n",
              "      <td>73.170732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.491200</td>\n",
              "      <td>0.541496</td>\n",
              "      <td>73.733583</td>\n",
              "      <td>73.733583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.528800</td>\n",
              "      <td>0.530911</td>\n",
              "      <td>73.170732</td>\n",
              "      <td>73.170732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.623300</td>\n",
              "      <td>0.525940</td>\n",
              "      <td>74.859287</td>\n",
              "      <td>74.859287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing: 1066it [00:03, 346.76it/s]\n",
            "tokenizing: 1066it [00:00, 1803.06it/s]\n",
            "tokenizing: 1066it [00:00, 1781.72it/s]\n",
            "tokenizing: 1066it [00:00, 1803.07it/s]\n",
            "tokenizing: 1066it [00:00, 1071.73it/s]\n",
            "tokenizing: 1066it [00:00, 1698.75it/s]\n",
            "tokenizing: 1066it [00:00, 1742.05it/s]\n",
            "tokenizing: 1066it [00:01, 1035.03it/s]\n",
            "tokenizing: 1066it [00:00, 1722.40it/s]\n",
            "tokenizing: 1066it [00:00, 1734.05it/s]\n",
            "There were missing keys in the checkpoint model loaded: ['prompt_model.plm.roberta.embeddings.word_embeddings.weight', 'prompt_model.plm.roberta.embeddings.position_embeddings.weight', 'prompt_model.plm.roberta.embeddings.token_type_embeddings.weight', 'prompt_model.plm.roberta.embeddings.LayerNorm.weight', 'prompt_model.plm.roberta.embeddings.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.0.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.0.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.0.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.0.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.0.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.0.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.0.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.0.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.0.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.0.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.0.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.0.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.0.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.0.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.1.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.1.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.1.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.1.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.1.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.1.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.1.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.1.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.1.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.1.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.1.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.1.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.1.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.1.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.2.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.2.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.2.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.2.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.2.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.2.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.2.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.2.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.2.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.2.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.2.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.2.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.2.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.2.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.3.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.3.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.3.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.3.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.3.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.3.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.3.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.3.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.3.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.3.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.3.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.3.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.3.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.3.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.4.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.4.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.4.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.4.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.4.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.4.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.4.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.4.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.4.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.4.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.4.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.4.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.4.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.4.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.5.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.5.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.5.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.5.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.5.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.5.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.5.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.5.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.5.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.5.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.5.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.5.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.5.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.5.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.6.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.6.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.6.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.6.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.6.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.6.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.6.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.6.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.6.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.6.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.6.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.6.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.6.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.6.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.7.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.7.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.7.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.7.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.7.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.7.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.7.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.7.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.7.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.7.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.7.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.7.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.7.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.7.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.8.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.8.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.8.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.8.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.8.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.8.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.8.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.8.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.8.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.8.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.8.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.8.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.8.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.8.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.9.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.9.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.9.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.9.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.9.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.9.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.9.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.9.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.9.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.9.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.9.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.9.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.9.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.9.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.10.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.10.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.10.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.10.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.10.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.10.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.10.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.10.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.10.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.10.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.10.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.10.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.10.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.10.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.11.attention.self.query.weight', 'prompt_model.plm.roberta.encoder.layer.11.attention.self.query.bias', 'prompt_model.plm.roberta.encoder.layer.11.attention.self.key.weight', 'prompt_model.plm.roberta.encoder.layer.11.attention.self.key.bias', 'prompt_model.plm.roberta.encoder.layer.11.attention.self.value.weight', 'prompt_model.plm.roberta.encoder.layer.11.attention.self.value.bias', 'prompt_model.plm.roberta.encoder.layer.11.attention.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.11.attention.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'prompt_model.plm.roberta.encoder.layer.11.intermediate.dense.weight', 'prompt_model.plm.roberta.encoder.layer.11.intermediate.dense.bias', 'prompt_model.plm.roberta.encoder.layer.11.output.dense.weight', 'prompt_model.plm.roberta.encoder.layer.11.output.dense.bias', 'prompt_model.plm.roberta.encoder.layer.11.output.LayerNorm.weight', 'prompt_model.plm.roberta.encoder.layer.11.output.LayerNorm.bias', 'prompt_model.plm.lm_head.bias', 'prompt_model.plm.lm_head.dense.weight', 'prompt_model.plm.lm_head.dense.bias', 'prompt_model.plm.lm_head.layer_norm.weight', 'prompt_model.plm.lm_head.layer_norm.bias', 'prompt_model.plm.lm_head.decoder.weight', 'prompt_model.plm.lm_head.decoder.bias', 'prompt_model.template.raw_embedding.weight', 'verbalizer.label_words_ids', 'verbalizer.words_ids_mask', 'verbalizer.label_words_mask'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.5867584550380707, metrics={'train_runtime': 254.2626, 'train_samples_per_second': 6.293, 'train_steps_per_second': 0.393, 'total_flos': 0.0, 'train_loss': 0.5867584550380707, 'epoch': 0.19})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate Prompt\n",
        "\n",
        "Now we can evaluate the trained prompt."
      ],
      "metadata": {
        "id": "ivUKGwQb3SBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.eval_prompt(args.backbone, args.dataset)\n",
        "print(eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "BMycdxHB3V-U",
        "outputId": "6ce01c9f-fa8d-40a0-a855-d19366f12209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing: 1066it [00:00, 1732.50it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/9 00:16 < 00:02, 0.43 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-Task evaluation\n",
        "\n",
        "Now let's do a cross-task evaluation. We evaluate the prompt trained on MNLI on SNLI."
      ],
      "metadata": {
        "id": "KHknR2sx3aUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_task_eval_results = trainer.cross_task_eval(args.backbone, 'rotten_tomatoes')\n",
        "print(cross_task_eval_results)"
      ],
      "metadata": {
        "id": "VoRhMsq33Zhs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}